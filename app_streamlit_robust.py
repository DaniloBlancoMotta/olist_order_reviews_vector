#!/usr/bin/env python3
"""
Dashboard de An√°lise de Sentimento e T√≥picos - Olist Reviews
Vers√£o robusta com tratamento de depend√™ncias
"""

import streamlit as st
import pandas as pd
import numpy as np
from collections import Counter
import re
from datetime import datetime

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Dashboard Olist Reviews",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Importa√ß√µes opcionais com fallback
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    st.warning("‚ö†Ô∏è Matplotlib/Seaborn n√£o dispon√≠vel. Usando gr√°ficos alternativos.")

try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    st.warning("‚ö†Ô∏è Plotly n√£o dispon√≠vel. Usando gr√°ficos b√°sicos.")

try:
    import nltk
    NLTK_AVAILABLE = True
    # Download dos recursos do NLTK
    try:
        nltk.download('punkt', quiet=True)
        nltk.download('stopwords', quiet=True)
    except:
        pass
except ImportError:
    NLTK_AVAILABLE = False
    st.warning("‚ö†Ô∏è NLTK n√£o dispon√≠vel. Usando stopwords b√°sicas.")

# Configura√ß√£o de estilo
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .section-header {
        font-size: 1.5rem;
        color: #1f77b4;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_and_preprocess_data():
    """
    Carrega e pr√©-processa os dados do dataset
    """
    try:
        # Carrega o dataset
        df = pd.read_csv('data/olist_order_reviews_dataset.csv')
        
        # Converte review_creation_date para datetime
        df['review_creation_date'] = pd.to_datetime(df['review_creation_date'], errors='coerce')
        
        # Remove linhas com data inv√°lida
        df = df.dropna(subset=['review_creation_date'])
        
        # Trata valores nulos na coluna review_comment_message
        df['review_comment_message'] = df['review_comment_message'].fillna('')
        
        # Filtra apenas reviews com coment√°rios v√°lidos
        df = df[df['review_comment_message'].str.len() > 10]
        
        # Adiciona colunas √∫teis
        df['year'] = df['review_creation_date'].dt.year
        df['month'] = df['review_creation_date'].dt.month
        df['year_month'] = df['review_creation_date'].dt.to_period('M')
        
        return df
    
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados: {e}")
        return None

def clean_text(text):
    """
    Limpa e pr√©-processa texto para an√°lise
    """
    if pd.isna(text) or text == '':
        return ''
    
    # Converte para min√∫sculas
    text = text.lower()
    
    # Remove pontua√ß√£o e n√∫meros
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    
    # Remove espa√ßos extras
    text = ' '.join(text.split())
    
    return text

def get_stopwords():
    """
    Retorna lista de stopwords em portugu√™s
    """
    if NLTK_AVAILABLE:
        try:
            from nltk.corpus import stopwords
            stop_words = set(stopwords.words('portuguese'))
            return stop_words
        except:
            pass
    
    # Fallback para lista b√°sica de stopwords em portugu√™s
    stop_words = {
        'a', 'o', 'e', '√©', 'de', 'do', 'da', 'em', 'um', 'para', 'com', 'n√£o', 'uma',
        'os', 'as', 'que', 'se', 'na', 'por', 'mais', 'as', 'como', 'mas', 'foi', 'ele',
        'das', 'tem', '√†', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'h√°', 'nos',
        'j√°', 'est√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 'entre',
        'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'suas', 'minha', 't√™m',
        'naquele', 'essas', 'esses', 'pelos', 'elas', 'estava', 'seja', 'qual', 'ser√°',
        'n√≥s', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse',
        'dele', 'tu', 'te', 'voc√™', 'voc√™s', 'lhe', 'lhes', 'meu', 'minha', 'meus',
        'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas',
        'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles',
        'aquelas', 'isto', 'aquilo', 'estou', 'est√°', 'estamos', 'est√£o', 'estive',
        'esteve', 'estivemos', 'estiveram', 'estava', 'est√°vamos', 'estavam', 'estivera',
        'estiv√©ramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estiv√©ssemos',
        'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'h√°', 'havemos',
        'h√£o', 'houve', 'houvemos', 'houveram', 'houvera', 'houv√©ramos', 'haja',
        'hajamos', 'hajam', 'houvesse', 'houv√©ssemos', 'houvessem', 'houver', 'houvermos',
        'houverem', 'houverei', 'houver√°', 'houveremos', 'houver√£o', 'houveria',
        'houver√≠amos', 'houveriam', 'sou', 'somos', 's√£o', 'era', '√©ramos', 'eram',
        'fui', 'foi', 'fomos', 'foram', 'fora', 'f√¥ramos', 'seja', 'sejamos', 'sejam',
        'fosse', 'f√¥ssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'ser√°',
        'seremos', 'ser√£o', 'seria', 'ser√≠amos', 'seriam', 'tenho', 'tem', 'temos',
        't√™m', 'tinha', 't√≠nhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram',
        'tivera', 'tiv√©ramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tiv√©ssemos',
        'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'ter√°', 'teremos',
        'ter√£o', 'teria', 'ter√≠amos', 'teriam'
    }
    
    return stop_words

def get_word_frequency(texts, stop_words, top_n=10):
    """
    Calcula a frequ√™ncia de palavras em uma lista de textos
    """
    all_words = []
    
    for text in texts:
        if pd.isna(text) or text == '':
            continue
        
        # Limpa o texto
        clean_text_str = clean_text(text)
        
        # Tokeniza
        words = clean_text_str.split()
        
        # Remove stopwords
        words = [word for word in words if word not in stop_words and len(word) > 2]
        
        all_words.extend(words)
    
    # Conta frequ√™ncia
    word_counts = Counter(all_words)
    
    # Retorna as top_n palavras mais frequentes
    return word_counts.most_common(top_n)

def simulate_vector_search(query, df, top_k=5):
    """
    Simula busca em banco vetorial
    """
    if not query or query.strip() == '':
        return []
    
    # Simula√ß√£o simples: busca por palavras-chave
    query_lower = query.lower()
    
    # Filtra reviews que cont√™m palavras da query
    matching_reviews = []
    
    for _, row in df.iterrows():
        review_text = str(row['review_comment_message']).lower()
        if any(word in review_text for word in query_lower.split()):
            matching_reviews.append({
                'review_score': row['review_score'],
                'review_comment_message': row['review_comment_message'][:200] + '...' if len(row['review_comment_message']) > 200 else row['review_comment_message'],
                'review_creation_date': row['review_creation_date'].strftime('%Y-%m-%d'),
                'similarity_score': np.random.uniform(0.7, 1.0)
            })
    
    # Ordena por score de similaridade e retorna top_k
    matching_reviews.sort(key=lambda x: x['similarity_score'], reverse=True)
    return matching_reviews[:top_k]

def create_simple_chart(data, title, x_label, y_label):
    """
    Cria gr√°fico simples usando streamlit
    """
    st.subheader(title)
    
    # Cria um DataFrame para o gr√°fico
    df_chart = pd.DataFrame(data)
    
    # Usa st.bar_chart se dispon√≠vel
    if len(df_chart) > 0:
        st.bar_chart(df_chart)
    else:
        st.write("Nenhum dado dispon√≠vel para visualiza√ß√£o")

def main():
    """
    Fun√ß√£o principal da aplica√ß√£o
    """
    # Cabe√ßalho
    st.markdown('<h1 class="main-header">üìä Dashboard de An√°lise de Sentimento e T√≥picos</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Insights r√°pidos sobre a percep√ß√£o do cliente, potencializado por busca sem√¢ntica</p>', unsafe_allow_html=True)
    
    # Carrega dados
    with st.spinner('üîÑ Carregando dados...'):
        df = load_and_preprocess_data()
    
    if df is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar os dados. Verifique se o arquivo existe.")
        return
    
    # Informa√ß√µes b√°sicas
    st.sidebar.markdown("## üìà Informa√ß√µes do Dataset")
    st.sidebar.metric("Total de Reviews", f"{len(df):,}")
    st.sidebar.metric("Per√≠odo", f"{df['year'].min()} - {df['year'].max()}")
    st.sidebar.metric("Score M√©dio", f"{df['review_score'].mean():.2f}")
    
    # 1. VIS√ÉO GERAL DA SATISFA√á√ÉO
    st.markdown('<h2 class="section-header">üéØ Vis√£o Geral da Satisfa√ß√£o</h2>', unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Score M√©dio", f"{df['review_score'].mean():.2f}")
    
    with col2:
        st.metric("Score Mediano", f"{df['review_score'].median():.1f}")
    
    with col3:
        st.metric("Score Modal", f"{df['review_score'].mode().iloc[0]:.0f}")
    
    with col4:
        st.metric("Desvio Padr√£o", f"{df['review_score'].std():.2f}")
    
    # Distribui√ß√£o das pontua√ß√µes
    st.subheader("üìä Distribui√ß√£o das Pontua√ß√µes")
    
    score_counts = df['review_score'].value_counts().sort_index()
    score_percentages = (score_counts / len(df) * 100).round(1)
    
    # Tabela de distribui√ß√£o
    dist_data = pd.DataFrame({
        'Score': score_counts.index,
        'Quantidade': score_counts.values,
        'Porcentagem (%)': score_percentages.values
    })
    
    st.dataframe(dist_data, use_container_width=True)
    
    # Gr√°fico simples
    if MATPLOTLIB_AVAILABLE:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Contagem absoluta
        ax1.bar(score_counts.index, score_counts.values, color='skyblue', alpha=0.7)
        ax1.set_title('Contagem de Reviews por Score')
        ax1.set_xlabel('Score')
        ax1.set_ylabel('Quantidade de Reviews')
        ax1.grid(True, alpha=0.3)
        
        # Porcentagem
        ax2.bar(score_percentages.index, score_percentages.values, color='lightcoral', alpha=0.7)
        ax2.set_title('Distribui√ß√£o Percentual por Score')
        ax2.set_xlabel('Score')
        ax2.set_ylabel('Porcentagem (%)')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)
    else:
        # Gr√°fico alternativo usando streamlit
        st.subheader("Contagem de Reviews por Score")
        st.bar_chart(score_counts)
        
        st.subheader("Distribui√ß√£o Percentual por Score")
        st.bar_chart(score_percentages)
    
    # Interpreta√ß√£o
    st.info("""
    **üí° Interpreta√ß√£o:** 
    - A maioria dos clientes est√° satisfeita (scores 4-5)
    - Scores baixos (1-2) indicam problemas que precisam de aten√ß√£o
    - A distribui√ß√£o mostra a qualidade geral do servi√ßo
    """)
    
    # 2. TEND√äNCIA DE SATISFA√á√ÉO AO LONGO DO TEMPO
    st.markdown('<h2 class="section-header">üìà Tend√™ncia de Satisfa√ß√£o ao Longo do Tempo</h2>', unsafe_allow_html=True)
    
    # Filtro de ano
    years = sorted(df['year'].unique())
    selected_year = st.selectbox("Selecione o ano para an√°lise:", years, index=len(years)-1)
    
    # Filtra dados por ano
    df_year = df[df['year'] == selected_year]
    
    if len(df_year) > 0:
        # Calcula m√©dia mensal
        monthly_avg = df_year.groupby('month')['review_score'].agg(['mean', 'count']).reset_index()
        monthly_avg.columns = ['M√™s', 'Score M√©dio', 'Quantidade de Reviews']
        
        # Tabela com dados
        st.subheader("üìã Dados Mensais")
        st.dataframe(monthly_avg, use_container_width=True)
        
        # Gr√°fico de linha
        if MATPLOTLIB_AVAILABLE:
            fig, ax = plt.subplots(figsize=(12, 6))
            
            ax.plot(monthly_avg['M√™s'], monthly_avg['Score M√©dio'], marker='o', linewidth=2, markersize=8, color='#1f77b4')
            ax.fill_between(monthly_avg['M√™s'], monthly_avg['Score M√©dio'], alpha=0.3, color='#1f77b4')
            
            ax.set_title(f'Evolu√ß√£o da Satisfa√ß√£o M√©dia - {selected_year}')
            ax.set_xlabel('M√™s')
            ax.set_ylabel('Score M√©dio')
            ax.grid(True, alpha=0.3)
            ax.set_xticks(range(1, 13))
            
            plt.tight_layout()
            st.pyplot(fig)
        else:
            # Gr√°fico alternativo
            st.subheader(f"Evolu√ß√£o da Satisfa√ß√£o M√©dia - {selected_year}")
            chart_data = pd.DataFrame({
                'M√™s': monthly_avg['M√™s'],
                'Score M√©dio': monthly_avg['Score M√©dio']
            }).set_index('M√™s')
            st.line_chart(chart_data)
        
        # An√°lise de tend√™ncias
        st.subheader("üîç An√°lise de Tend√™ncias")
        
        # Identifica picos e quedas
        mean_score = monthly_avg['Score M√©dio'].mean()
        high_months = monthly_avg[monthly_avg['Score M√©dio'] > mean_score + 0.2]
        low_months = monthly_avg[monthly_avg['Score M√©dio'] < mean_score - 0.2]
        
        col1, col2 = st.columns(2)
        
        with col1:
            if len(high_months) > 0:
                st.success(f"üìà **Meses com Alta Satisfa√ß√£o:** {', '.join(map(str, high_months['M√™s'].tolist()))}")
            else:
                st.info("üìä N√£o foram identificados meses com satisfa√ß√£o excepcionalmente alta")
        
        with col2:
            if len(low_months) > 0:
                st.error(f"üìâ **Meses com Baixa Satisfa√ß√£o:** {', '.join(map(str, low_months['M√™s'].tolist()))}")
            else:
                st.info("üìä N√£o foram identificados meses com satisfa√ß√£o excepcionalmente baixa")
    
    # 3. AN√ÅLISE DE T√ìPICOS E BUSCA SEM√ÇNTICA
    st.markdown('<h2 class="section-header">üîç An√°lise Aprofundada dos Coment√°rios (Simula√ß√£o de Busca Vetorial)</h2>', unsafe_allow_html=True)
    
    # Obt√©m stopwords
    stop_words = get_stopwords()
    
    # Separa reviews positivos e negativos
    positive_reviews = df[df['review_score'].isin([4, 5])]['review_comment_message'].tolist()
    negative_reviews = df[df['review_score'].isin([1, 2])]['review_comment_message'].tolist()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üòä O que os clientes mais elogiam (Score 4-5)")
        
        if len(positive_reviews) > 0:
            positive_words = get_word_frequency(positive_reviews, stop_words, top_n=10)
            
            # Tabela de palavras positivas
            pos_df = pd.DataFrame(positive_words, columns=['Palavra', 'Frequ√™ncia'])
            st.dataframe(pos_df, use_container_width=True)
            
            if MATPLOTLIB_AVAILABLE:
                # Gr√°fico de palavras positivas
                words, counts = zip(*positive_words)
                
                fig, ax = plt.subplots(figsize=(10, 6))
                bars = ax.barh(range(len(words)), counts, color='lightgreen', alpha=0.7)
                ax.set_yticks(range(len(words)))
                ax.set_yticklabels(words)
                ax.set_xlabel('Frequ√™ncia')
                ax.set_title('Palavras Mais Frequentes em Reviews Positivos')
                ax.invert_yaxis()
                
                plt.tight_layout()
                st.pyplot(fig)
            
            st.info("""
            **üí° Com Banco Vetorial:** 
            Com um banco vetorial real, poder√≠amos clusterizar semanticamente esses reviews 
            para identificar t√≥picos emergentes ou usar modelos de topic modeling mais avan√ßados.
            """)
        else:
            st.warning("N√£o h√° reviews positivos suficientes para an√°lise")
    
    with col2:
        st.subheader("üòû O que mais causa insatisfa√ß√£o (Score 1-2)")
        
        if len(negative_reviews) > 0:
            negative_words = get_word_frequency(negative_reviews, stop_words, top_n=10)
            
            # Tabela de palavras negativas
            neg_df = pd.DataFrame(negative_words, columns=['Palavra', 'Frequ√™ncia'])
            st.dataframe(neg_df, use_container_width=True)
            
            if MATPLOTLIB_AVAILABLE:
                # Gr√°fico de palavras negativas
                words, counts = zip(*negative_words)
                
                fig, ax = plt.subplots(figsize=(10, 6))
                bars = ax.barh(range(len(words)), counts, color='lightcoral', alpha=0.7)
                ax.set_yticks(range(len(words)))
                ax.set_yticklabels(words)
                ax.set_xlabel('Frequ√™ncia')
                ax.set_title('Palavras Mais Frequentes em Reviews Negativos')
                ax.invert_yaxis()
                
                plt.tight_layout()
                st.pyplot(fig)
            
            st.info("""
            **üí° Com Banco Vetorial:** 
            Similar ao anterior, com um banco vetorial, poder√≠amos identificar problemas raiz 
            atrav√©s da similaridade sem√¢ntica de frases e n√£o apenas de palavras soltas.
            """)
        else:
            st.warning("N√£o h√° reviews negativos suficientes para an√°lise")
    
    # 4. SIMULA√á√ÉO DE BUSCA DE REVIEWS SIMILARES
    st.markdown('<h2 class="section-header">üîé Simula√ß√£o de Busca de Reviews Similares</h2>', unsafe_allow_html=True)
    
    st.info("""
    **üí° Como Funciona a Busca Vetorial:**
    Em um cen√°rio real, o texto de busca seria vetorizado (embedding) e essa embedding seria 
    usada para consultar o banco vetorial, retornando reviews com vetores mais pr√≥ximos (maior similaridade cosseno).
    """)
    
    # Campo de busca
    search_query = st.text_input(
        "Buscar Reviews Similares (Simula√ß√£o de Banco Vetorial):",
        placeholder="Digite palavras-chave para buscar reviews similares..."
    )
    
    col1, col2 = st.columns([1, 4])
    
    with col1:
        search_button = st.button("üîç Buscar", type="primary")
    
    with col2:
        if search_button and search_query:
            st.write(f"**Simulando busca no banco vetorial por reviews similares a:** '{search_query}'")
            st.write("Em um ambiente real, os 5 reviews mais similares seriam retornados aqui.")
            
            # Simula busca
            similar_reviews = simulate_vector_search(search_query, df, top_k=5)
            
            if similar_reviews:
                st.subheader("üìã Reviews Encontrados (Simula√ß√£o)")
                
                for i, review in enumerate(similar_reviews, 1):
                    with st.expander(f"Review {i} - Score: {review['review_score']} - Similaridade: {review['similarity_score']:.3f}"):
                        st.write(f"**Data:** {review['review_creation_date']}")
                        st.write(f"**Coment√°rio:** {review['review_comment_message']}")
            else:
                st.warning("Nenhum review similar encontrado para esta busca.")
    
    # 5. RESUMO E RECOMENDA√á√ïES
    st.markdown('<h2 class="section-header">üìã Resumo e Recomenda√ß√µes</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üéØ Principais Insights")
        
        # Calcula insights
        total_reviews = len(df)
        positive_pct = len(df[df['review_score'].isin([4, 5])]) / total_reviews * 100
        negative_pct = len(df[df['review_score'].isin([1, 2])]) / total_reviews * 100
        
        st.metric("Satisfa√ß√£o Geral", f"{positive_pct:.1f}%", f"{positive_pct - 50:.1f}%")
        st.metric("Insatisfa√ß√£o", f"{negative_pct:.1f}%", f"{negative_pct - 20:.1f}%")
        
        # Recomenda√ß√µes baseadas nos dados
        if positive_pct > 70:
            st.success("‚úÖ **Excelente satisfa√ß√£o geral!** Continue mantendo a qualidade.")
        elif positive_pct > 50:
            st.info("üìä **Satisfa√ß√£o moderada.** H√° espa√ßo para melhorias.")
        else:
            st.error("‚ö†Ô∏è **Baixa satisfa√ß√£o.** A√ß√£o imediata necess√°ria.")
    
    with col2:
        st.subheader("üöÄ Pr√≥ximos Passos Sugeridos")
        
        recommendations = []
        
        if negative_pct > 20:
            recommendations.append("üîç Investigar causas da insatisfa√ß√£o")
        
        if df['review_score'].std() > 1.5:
            recommendations.append("üìä Analisar inconsist√™ncias na qualidade")
        
        if len(negative_reviews) > 100:
            recommendations.append("üéØ Implementar melhorias baseadas em feedback negativo")
        
        if len(positive_reviews) > 100:
            recommendations.append("üåü Refor√ßar pontos positivos identificados")
        
        if not recommendations:
            recommendations.append("üìà Manter monitoramento cont√≠nuo")
        
        for rec in recommendations:
            st.write(f"‚Ä¢ {rec}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>üìä Dashboard criado para an√°lise de sentimentos da Olist</p>
        <p>üí° Potencializado por simula√ß√£o de banco vetorial para busca sem√¢ntica</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 