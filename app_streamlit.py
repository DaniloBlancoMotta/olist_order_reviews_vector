#!/usr/bin/env python3
"""
Dashboard de An√°lise de Sentimento e T√≥picos - Olist Reviews
Aplica√ß√£o Streamlit para insights r√°pidos sobre percep√ß√£o do cliente
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import re
import nltk
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os

# Adiciona o diret√≥rio src ao path para importar os m√≥dulos
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Importa√ß√µes dos m√≥dulos do projeto
from olist_reviews.config import Config
from olist_reviews.rag.vector_store import VectorStore
from olist_reviews.sentiment.sentiment_analyzer import SentimentAnalyzer

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Dashboard Olist Reviews",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Download dos recursos do NLTK (executar apenas uma vez)
@st.cache_resource
def download_nltk_resources():
    """Download dos recursos necess√°rios do NLTK"""
    try:
        nltk.download('punkt', quiet=True)
        nltk.download('stopwords', quiet=True)
    except:
        st.warning("‚ö†Ô∏è Erro ao baixar recursos do NLTK. Algumas funcionalidades podem n√£o funcionar.")

download_nltk_resources()

# Configura√ß√£o de estilo
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .section-header {
        font-size: 1.5rem;
        color: #1f77b4;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_and_preprocess_data():
    """
    Carrega e pr√©-processa os dados do dataset usando o caminho correto
    """
    try:
        # Usa o caminho configurado no Config
        dataset_path = Config.DATASET_PATH
        
        # Verifica se o arquivo existe
        if not os.path.exists(dataset_path):
            st.error(f"‚ùå Arquivo n√£o encontrado: {dataset_path}")
            st.info("Verifique se o arquivo olist_order_reviews_dataset.csv est√° na pasta data/")
            return None
        
        # Carrega o dataset
        df = pd.read_csv(dataset_path)
        
        # Converte review_creation_date para datetime
        df['review_creation_date'] = pd.to_datetime(df['review_creation_date'], errors='coerce')
        
        # Remove linhas com data inv√°lida
        df = df.dropna(subset=['review_creation_date'])
        
        # Trata valores nulos na coluna review_comment_message
        df['review_comment_message'] = df['review_comment_message'].fillna('')
        
        # Filtra apenas reviews com coment√°rios v√°lidos
        df = df[df['review_comment_message'].str.len() > 10]
        
        # Adiciona colunas √∫teis
        df['year'] = df['review_creation_date'].dt.year
        df['month'] = df['review_creation_date'].dt.month
        df['year_month'] = df['review_creation_date'].dt.to_period('M')
        
        return df
    
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados: {e}")
        return None

@st.cache_resource
def initialize_vector_store():
    """
    Inicializa o banco vetorial
    """
    try:
        vector_store = VectorStore()
        
        # Verifica se o √≠ndice existe
        if os.path.exists(f"{Config.FAISS_INDEX_PATH}.faiss"):
            st.info("üîÑ Carregando banco vetorial existente...")
            vector_store.load_index()
        else:
            st.info("üîÑ Construindo banco vetorial...")
            vector_store.build_index()
        
        return vector_store
    except Exception as e:
        st.error(f"‚ùå Erro ao inicializar banco vetorial: {e}")
        return None

@st.cache_resource
def initialize_sentiment_analyzer():
    """
    Inicializa o analisador de sentimentos
    """
    try:
        return SentimentAnalyzer()
    except Exception as e:
        st.error(f"‚ùå Erro ao inicializar analisador de sentimentos: {e}")
        return None

def clean_text(text):
    """
    Limpa e pr√©-processa texto para an√°lise
    """
    if pd.isna(text) or text == '':
        return ''
    
    # Converte para min√∫sculas
    text = text.lower()
    
    # Remove pontua√ß√£o e n√∫meros
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    
    # Remove espa√ßos extras
    text = ' '.join(text.split())
    
    return text

def get_stopwords():
    """
    Retorna lista de stopwords em portugu√™s
    """
    try:
        from nltk.corpus import stopwords
        stop_words = set(stopwords.words('portuguese'))
    except:
        # Fallback para lista b√°sica de stopwords em portugu√™s
        stop_words = {
            'a', 'o', 'e', '√©', 'de', 'do', 'da', 'em', 'um', 'para', 'com', 'n√£o', 'uma',
            'os', 'as', 'que', 'se', 'na', 'por', 'mais', 'as', 'como', 'mas', 'foi', 'ele',
            'das', 'tem', '√†', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'h√°', 'nos',
            'j√°', 'est√°', 'eu', 'tamb√©m', 's√≥', 'pelo', 'pela', 'at√©', 'isso', 'ela', 'entre',
            'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'suas', 'minha', 't√™m',
            'naquele', 'essas', 'esses', 'pelos', 'elas', 'estava', 'seja', 'qual', 'ser√°',
            'n√≥s', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse',
            'dele', 'tu', 'te', 'voc√™', 'voc√™s', 'lhe', 'lhes', 'meu', 'minha', 'meus',
            'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas',
            'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles',
            'aquelas', 'isto', 'aquilo', 'estou', 'est√°', 'estamos', 'est√£o', 'estive',
            'esteve', 'estivemos', 'estiveram', 'estava', 'est√°vamos', 'estavam', 'estivera',
            'estiv√©ramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estiv√©ssemos',
            'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'h√°', 'havemos',
            'h√£o', 'houve', 'houvemos', 'houveram', 'houvera', 'houv√©ramos', 'haja',
            'hajamos', 'hajam', 'houvesse', 'houv√©ssemos', 'houvessem', 'houver', 'houvermos',
            'houverem', 'houverei', 'houver√°', 'houveremos', 'houver√£o', 'houveria',
            'houver√≠amos', 'houveriam', 'sou', 'somos', 's√£o', 'era', '√©ramos', 'eram',
            'fui', 'foi', 'fomos', 'foram', 'fora', 'f√¥ramos', 'seja', 'sejamos', 'sejam',
            'fosse', 'f√¥ssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'ser√°',
            'seremos', 'ser√£o', 'seria', 'ser√≠amos', 'seriam', 'tenho', 'tem', 'temos',
            't√™m', 'tinha', 't√≠nhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram',
            'tivera', 'tiv√©ramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tiv√©ssemos',
            'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'ter√°', 'teremos',
            'ter√£o', 'teria', 'ter√≠amos', 'teriam'
        }
    
    return stop_words

def get_word_frequency(texts, stop_words, top_n=10):
    """
    Calcula a frequ√™ncia de palavras em uma lista de textos
    """
    all_words = []
    
    for text in texts:
        if pd.isna(text) or text == '':
            continue
        
        # Limpa o texto
        clean_text_str = clean_text(text)
        
        # Tokeniza
        words = clean_text_str.split()
        
        # Remove stopwords
        words = [word for word in words if word not in stop_words and len(word) > 2]
        
        all_words.extend(words)
    
    # Conta frequ√™ncia
    word_counts = Counter(all_words)
    
    # Retorna as top_n palavras mais frequentes
    return word_counts.most_common(top_n)

def search_similar_reviews_real(query, vector_store, top_k=5):
    """
    Busca reviews similares usando o banco vetorial real
    """
    if not query or query.strip() == '':
        return []
    
    try:
        # Busca no banco vetorial
        similar_reviews = vector_store.search_similar_reviews(query, k=top_k)
        
        # Formata os resultados
        formatted_results = []
        for review in similar_reviews:
            formatted_results.append({
                'review_score': review.get('review_score', 0),
                'review_comment_message': review.get('review_comment_message', '')[:200] + '...' if len(review.get('review_comment_message', '')) > 200 else review.get('review_comment_message', ''),
                'review_creation_date': pd.to_datetime(review.get('review_creation_date')).strftime('%Y-%m-%d') if review.get('review_creation_date') else 'N/A',
                'similarity_score': review.get('similarity_score', 0)
            })
        
        return formatted_results
    except Exception as e:
        st.error(f"‚ùå Erro na busca vetorial: {e}")
        return []

def main():
    """
    Fun√ß√£o principal da aplica√ß√£o
    """
    # Cabe√ßalho
    st.markdown('<h1 class="main-header">üìä Dashboard de An√°lise de Sentimento e T√≥picos</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Insights r√°pidos sobre a percep√ß√£o do cliente, potencializado por busca sem√¢ntica com banco vetorial real</p>', unsafe_allow_html=True)
    
    # Inicializa componentes
    with st.spinner('üîÑ Inicializando componentes...'):
        # Carrega dados
        df = load_and_preprocess_data()
        
        # Inicializa banco vetorial
        vector_store = initialize_vector_store()
        
        # Inicializa analisador de sentimentos
        sentiment_analyzer = initialize_sentiment_analyzer()
    
    if df is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar os dados. Verifique se o arquivo existe.")
        return
    
    if vector_store is None:
        st.warning("‚ö†Ô∏è Banco vetorial n√£o dispon√≠vel. Algumas funcionalidades podem n√£o funcionar.")
    
    # Informa√ß√µes b√°sicas
    st.sidebar.markdown("## üìà Informa√ß√µes do Dataset")
    st.sidebar.metric("Total de Reviews", f"{len(df):,}")
    st.sidebar.metric("Per√≠odo", f"{df['year'].min()} - {df['year'].max()}")
    st.sidebar.metric("Score M√©dio", f"{df['review_score'].mean():.2f}")
    
    if vector_store:
        st.sidebar.markdown("## üîç Banco Vetorial")
        st.sidebar.success("‚úÖ Banco vetorial carregado")
        st.sidebar.metric("Reviews Indexados", f"{len(vector_store.reviews_data):,}")
    
    if sentiment_analyzer:
        st.sidebar.markdown("## üòä An√°lise de Sentimentos")
        st.sidebar.success("‚úÖ Analisador de sentimentos carregado")
    
    # 1. VIS√ÉO GERAL DA SATISFA√á√ÉO
    st.markdown('<h2 class="section-header">üéØ Vis√£o Geral da Satisfa√ß√£o</h2>', unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Score M√©dio", f"{df['review_score'].mean():.2f}")
    
    with col2:
        st.metric("Score Mediano", f"{df['review_score'].median():.1f}")
    
    with col3:
        st.metric("Score Modal", f"{df['review_score'].mode().iloc[0]:.0f}")
    
    with col4:
        st.metric("Desvio Padr√£o", f"{df['review_score'].std():.2f}")
    
    # Distribui√ß√£o das pontua√ß√µes
    st.subheader("üìä Distribui√ß√£o das Pontua√ß√µes")
    
    score_counts = df['review_score'].value_counts().sort_index()
    score_percentages = (score_counts / len(df) * 100).round(1)
    
    # Gr√°fico de barras
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Contagem absoluta
    ax1.bar(score_counts.index, score_counts.values, color='skyblue', alpha=0.7)
    ax1.set_title('Contagem de Reviews por Score')
    ax1.set_xlabel('Score')
    ax1.set_ylabel('Quantidade de Reviews')
    ax1.grid(True, alpha=0.3)
    
    # Porcentagem
    ax2.bar(score_percentages.index, score_percentages.values, color='lightcoral', alpha=0.7)
    ax2.set_title('Distribui√ß√£o Percentual por Score')
    ax2.set_xlabel('Score')
    ax2.set_ylabel('Porcentagem (%)')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # Interpreta√ß√£o
    st.info("""
    **üí° Interpreta√ß√£o:** 
    - A maioria dos clientes est√° satisfeita (scores 4-5)
    - Scores baixos (1-2) indicam problemas que precisam de aten√ß√£o
    - A distribui√ß√£o mostra a qualidade geral do servi√ßo
    """)
    
    # 2. TEND√äNCIA DE SATISFA√á√ÉO AO LONGO DO TEMPO
    st.markdown('<h2 class="section-header">üìà Tend√™ncia de Satisfa√ß√£o ao Longo do Tempo</h2>', unsafe_allow_html=True)
    
    # Filtro de ano
    years = sorted(df['year'].unique())
    selected_year = st.selectbox("Selecione o ano para an√°lise:", years, index=len(years)-1)
    
    # Filtra dados por ano
    df_year = df[df['year'] == selected_year]
    
    if len(df_year) > 0:
        # Calcula m√©dia mensal
        monthly_avg = df_year.groupby('month')['review_score'].agg(['mean', 'count']).reset_index()
        monthly_avg.columns = ['M√™s', 'Score M√©dio', 'Quantidade de Reviews']
        
        # Gr√°fico de linha
        fig, ax = plt.subplots(figsize=(12, 6))
        
        ax.plot(monthly_avg['M√™s'], monthly_avg['Score M√©dio'], marker='o', linewidth=2, markersize=8, color='#1f77b4')
        ax.fill_between(monthly_avg['M√™s'], monthly_avg['Score M√©dio'], alpha=0.3, color='#1f77b4')
        
        ax.set_title(f'Evolu√ß√£o da Satisfa√ß√£o M√©dia - {selected_year}')
        ax.set_xlabel('M√™s')
        ax.set_ylabel('Score M√©dio')
        ax.grid(True, alpha=0.3)
        ax.set_xticks(range(1, 13))
        
        # Adiciona anota√ß√µes para picos e quedas
        for i, row in monthly_avg.iterrows():
            ax.annotate(f"{row['Score M√©dio']:.2f}", 
                       (row['M√™s'], row['Score M√©dio']), 
                       textcoords="offset points", 
                       xytext=(0,10), 
                       ha='center')
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # Tabela com dados
        st.subheader("üìã Dados Mensais")
        st.dataframe(monthly_avg, use_container_width=True)
        
        # An√°lise de tend√™ncias
        st.subheader("üîç An√°lise de Tend√™ncias")
        
        # Identifica picos e quedas
        mean_score = monthly_avg['Score M√©dio'].mean()
        high_months = monthly_avg[monthly_avg['Score M√©dio'] > mean_score + 0.2]
        low_months = monthly_avg[monthly_avg['Score M√©dio'] < mean_score - 0.2]
        
        col1, col2 = st.columns(2)
        
        with col1:
            if len(high_months) > 0:
                st.success(f"üìà **Meses com Alta Satisfa√ß√£o:** {', '.join(map(str, high_months['M√™s'].tolist()))}")
            else:
                st.info("üìä N√£o foram identificados meses com satisfa√ß√£o excepcionalmente alta")
        
        with col2:
            if len(low_months) > 0:
                st.error(f"üìâ **Meses com Baixa Satisfa√ß√£o:** {', '.join(map(str, low_months['M√™s'].tolist()))}")
            else:
                st.info("üìä N√£o foram identificados meses com satisfa√ß√£o excepcionalmente baixa")
    
    # 3. AN√ÅLISE DE T√ìPICOS E BUSCA SEM√ÇNTICA
    st.markdown('<h2 class="section-header">üîç An√°lise Aprofundada dos Coment√°rios (Simula√ß√£o de Busca Vetorial)</h2>', unsafe_allow_html=True)
    
    # Obt√©m stopwords
    stop_words = get_stopwords()
    
    # Separa reviews positivos e negativos
    positive_reviews = df[df['review_score'].isin([4, 5])]['review_comment_message'].tolist()
    negative_reviews = df[df['review_score'].isin([1, 2])]['review_comment_message'].tolist()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üòä O que os clientes mais elogiam (Score 4-5)")
        
        if len(positive_reviews) > 0:
            positive_words = get_word_frequency(positive_reviews, stop_words, top_n=10)
            
            # Gr√°fico de palavras positivas
            words, counts = zip(*positive_words)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.barh(range(len(words)), counts, color='lightgreen', alpha=0.7)
            ax.set_yticks(range(len(words)))
            ax.set_yticklabels(words)
            ax.set_xlabel('Frequ√™ncia')
            ax.set_title('Palavras Mais Frequentes em Reviews Positivos')
            ax.invert_yaxis()
            
            # Adiciona valores nas barras
            for i, (bar, count) in enumerate(zip(bars, counts)):
                ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, 
                       str(count), ha='left', va='center')
            
            plt.tight_layout()
            st.pyplot(fig)
            
            st.info("""
            **üí° Com Banco Vetorial:** 
            Com um banco vetorial real, poder√≠amos clusterizar semanticamente esses reviews 
            para identificar t√≥picos emergentes ou usar modelos de topic modeling mais avan√ßados.
            """)
        else:
            st.warning("N√£o h√° reviews positivos suficientes para an√°lise")
    
    with col2:
        st.subheader("üòû O que mais causa insatisfa√ß√£o (Score 1-2)")
        
        if len(negative_reviews) > 0:
            negative_words = get_word_frequency(negative_reviews, stop_words, top_n=10)
            
            # Gr√°fico de palavras negativas
            words, counts = zip(*negative_words)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.barh(range(len(words)), counts, color='lightcoral', alpha=0.7)
            ax.set_yticks(range(len(words)))
            ax.set_yticklabels(words)
            ax.set_xlabel('Frequ√™ncia')
            ax.set_title('Palavras Mais Frequentes em Reviews Negativos')
            ax.invert_yaxis()
            
            # Adiciona valores nas barras
            for i, (bar, count) in enumerate(zip(bars, counts)):
                ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, 
                       str(count), ha='left', va='center')
            
            plt.tight_layout()
            st.pyplot(fig)
            
            st.info("""
            **üí° Com Banco Vetorial:** 
            Similar ao anterior, com um banco vetorial, poder√≠amos identificar problemas raiz 
            atrav√©s da similaridade sem√¢ntica de frases e n√£o apenas de palavras soltas.
            """)
        else:
            st.warning("N√£o h√° reviews negativos suficientes para an√°lise")
    
    # 4. BUSCA DE REVIEWS SIMILARES COM BANCO VETORIAL REAL
    st.markdown('<h2 class="section-header">üîé Busca de Reviews Similares com Banco Vetorial Real</h2>', unsafe_allow_html=True)
    
    if vector_store:
        st.success("""
        **‚úÖ Banco Vetorial Ativo:** 
        O sistema est√° usando um banco vetorial FAISS real com embeddings sem√¢nticos para encontrar 
        reviews similares baseados no significado, n√£o apenas em palavras-chave.
        """)
        
        # Campo de busca
        search_query = st.text_input(
            "Buscar Reviews Similares (Banco Vetorial Real):",
            placeholder="Digite palavras-chave para buscar reviews similares..."
        )
        
        col1, col2 = st.columns([1, 4])
        
        with col1:
            search_button = st.button("üîç Buscar", type="primary")
        
        with col2:
            if search_button and search_query:
                with st.spinner('üîç Buscando no banco vetorial...'):
                    similar_reviews = search_similar_reviews_real(search_query, vector_store, top_k=5)
                
                if similar_reviews:
                    st.subheader("üìã Reviews Encontrados (Banco Vetorial Real)")
                    
                    for i, review in enumerate(similar_reviews, 1):
                        with st.expander(f"Review {i} - Score: {review['review_score']} - Similaridade: {review['similarity_score']:.3f}"):
                            st.write(f"**Data:** {review['review_creation_date']}")
                            st.write(f"**Coment√°rio:** {review['review_comment_message']}")
                            
                            # An√°lise de sentimento se dispon√≠vel
                            if sentiment_analyzer:
                                try:
                                    sentiment = sentiment_analyzer.analyze_text_sentiment(review['review_comment_message'])
                                    st.write(f"**An√°lise de Sentimento:** {sentiment['sentiment']} (Confian√ßa: {sentiment['confidence']:.2f})")
                                except:
                                    pass
                else:
                    st.warning("Nenhum review similar encontrado para esta busca.")
    else:
        st.error("‚ùå Banco vetorial n√£o dispon√≠vel. N√£o √© poss√≠vel realizar buscas sem√¢nticas.")
        st.info("Verifique se os arquivos do banco vetorial est√£o presentes na pasta data/")
    
    # 5. RESUMO E RECOMENDA√á√ïES
    st.markdown('<h2 class="section-header">üìã Resumo e Recomenda√ß√µes</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üéØ Principais Insights")
        
        # Calcula insights
        total_reviews = len(df)
        positive_pct = len(df[df['review_score'].isin([4, 5])]) / total_reviews * 100
        negative_pct = len(df[df['review_score'].isin([1, 2])]) / total_reviews * 100
        
        st.metric("Satisfa√ß√£o Geral", f"{positive_pct:.1f}%", f"{positive_pct - 50:.1f}%")
        st.metric("Insatisfa√ß√£o", f"{negative_pct:.1f}%", f"{negative_pct - 20:.1f}%")
        
        # Recomenda√ß√µes baseadas nos dados
        if positive_pct > 70:
            st.success("‚úÖ **Excelente satisfa√ß√£o geral!** Continue mantendo a qualidade.")
        elif positive_pct > 50:
            st.info("üìä **Satisfa√ß√£o moderada.** H√° espa√ßo para melhorias.")
        else:
            st.error("‚ö†Ô∏è **Baixa satisfa√ß√£o.** A√ß√£o imediata necess√°ria.")
    
    with col2:
        st.subheader("üöÄ Pr√≥ximos Passos Sugeridos")
        
        recommendations = []
        
        if negative_pct > 20:
            recommendations.append("üîç Investigar causas da insatisfa√ß√£o")
        
        if df['review_score'].std() > 1.5:
            recommendations.append("üìä Analisar inconsist√™ncias na qualidade")
        
        if len(negative_reviews) > 100:
            recommendations.append("üéØ Implementar melhorias baseadas em feedback negativo")
        
        if len(positive_reviews) > 100:
            recommendations.append("üåü Refor√ßar pontos positivos identificados")
        
        if not recommendations:
            recommendations.append("üìà Manter monitoramento cont√≠nuo")
        
        for rec in recommendations:
            st.write(f"‚Ä¢ {rec}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>üìä Dashboard criado para an√°lise de sentimentos da Olist</p>
        <p>üí° Potencializado por simula√ß√£o de banco vetorial para busca sem√¢ntica</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 